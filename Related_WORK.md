Existing AI-Driven Border Surveillance Systems
Current border security technologies heavily rely on AI for detection and monitoring, but often prioritize enforcement over humanitarian concerns:
•  Anduril Industries’ Lattice Platform and Autonomous Surveillance Towers: Deployed extensively along the U.S.-Mexico border (over 300 towers by 2025), these systems use multi-sensor integration (radar, cameras, AI) to detect and classify humans vs. animals/vehicles. Critics highlight ethical issues, including pushing migrants into dangerous routes, increasing deaths, and normalizing mass surveillance without sufficient privacy protections.
•  U.S. Customs and Border Protection (CBP) Autonomous Systems: AI-powered “virtual wall” initiatives automate scanning and alerting, but raise concerns about algorithmic bias, privacy erosion, and disproportionate impacts on vulnerable groups.
Ethical Criticisms of AI in Border Control
Numerous reports and studies point to human rights risks in existing deployments:
•  AI surveillance at borders (e.g., EU projects like EUROSUR, iBorderCtrl) has been criticized for bias in training data, leading to discriminatory outcomes, invasion of privacy, and subtle erosion of rights such as freedom of movement and non-discrimination.
•  Organizations like Amnesty International, EFF, and ACLU argue that AI tools exacerbate racialized impacts, restrict asylum access, and create barriers for refugees, often without adequate accountability or transparency.
Starlink in Remote and Humanitarian Contexts
Starlink has demonstrated value in low-connectivity scenarios:
•  Used for rapid connectivity in disaster response, refugee camps, telehealth, and humanitarian aid (e.g., Ukraine crisis, natural disasters).
•  In border contexts, explored by CBP for officer communications and remote monitoring, highlighting low-latency advantages but primarily in enforcement-focused applications.
Non-Facial Behavior Recognition in Surveillance
AI for human activity recognition (HAR) without facial biometrics:
•  Frameworks focus on gait, posture, and movement patterns for anomaly detection in videos.
•  Commercial systems (e.g., viisights, Scylla) detect behaviors like violence or suspicious activity, but often in security contexts without built-in bias mitigation or co-governance.
In contrast, this LORI Framework proposal differentiates by prioritizing humanitarian rescue, transparent co-governance (e.g., joint dashboards with human rights observers), explicit bias avoidance in semantic behavior recognition, and non-militarized deployment—addressing gaps in existing systems that emphasize enforcement and surveillance over life-saving and ethical safeguards.
